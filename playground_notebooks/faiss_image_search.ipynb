{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Embedding Similarity Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating image embeddings with features extracted using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following is just a helper function used later to combine our organized (foldered by class) images into one big folder (unorganized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code that will merge the folders of the test images\n",
    "# Function to create new folder if not exists\n",
    "def merge_folders(src, dst=None) -> None:\n",
    "    '''merge_folders combine the files from multiple directories of a parent folder into one destination folder\n",
    "\n",
    "    Args:\n",
    "        src (str): Path to the main folder holding the folders you want to combine \n",
    "        dst (str, optional): Path where the destination folder is saved. Defaults to None.\n",
    "    '''\n",
    "    # helper fxn\n",
    "    def make_new_folder(folder_name, parent_folder):\n",
    "        path = os.path.join(parent_folder, folder_name)\n",
    "        # Create the folder 'new_folder' in parent_folder\n",
    "        try:\n",
    "            mode = 0o777            # mode of the folder\n",
    "            os.mkdir(path, mode)    # Create folder\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "\n",
    "    # list of folders to be merged\n",
    "    list_dir = os.listdir(src)\n",
    "\n",
    "    # enumerate on list_dir to get the content of all the folders and store\n",
    "    # it in a dictionary\n",
    "    content_list = {}\n",
    "    for index, val in enumerate(list_dir):\n",
    "        path = os.path.join(src, val)\n",
    "        content_list[ list_dir[index] ] = os.listdir(path)\n",
    "\n",
    "    # folder name in which all the content will be merged\n",
    "    merge_folder = src.split('/')[-1] + \"merge_folder\"\n",
    "    \n",
    "    if dst is None:\n",
    "        # place the merged folder next to the source folder\n",
    "        merge_folder_path = os.path.join(os.path.dirname(src), merge_folder)\n",
    "    else:\n",
    "        merge_folder_path = os.path.join(dst, merge_folder)\n",
    "    # create merge_folder if not exists\n",
    "    make_new_folder(merge_folder, src)\n",
    "\n",
    "    # loop through the list of folders\n",
    "    for sub_dir in content_list:\n",
    "        # loop through the contents of the list of folders\n",
    "        for contents in content_list[sub_dir]:\n",
    "            # make the path of the content to move\n",
    "            path_to_content = sub_dir + \"/\" + contents\n",
    "            # make the path with the current folder\n",
    "            dir_to_move = os.path.join(src, path_to_content)\n",
    "            # rename original file to have subfolder name in filename\n",
    "            pathNewName = os.path.join(src, sub_dir + \"/\" + sub_dir + '_' + contents)\n",
    "            os.rename(dir_to_move, pathNewName)\n",
    "            # move original file to merge_folder\n",
    "            shutil.copy(pathNewName, merge_folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a sample dataset of images, MNIST from github and unzip/organize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to store them as image (jpg) files to simulate input of datasets to the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mnist jpg images from GitHub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'MNIST-JPG'...\n"
     ]
    }
   ],
   "source": [
    "if \"MNIST\" not in os.listdir('.'):\n",
    "    print(\"Downloading mnist jpg images from GitHub\")\n",
    "    # Download mnist images from this git repo\n",
    "    os.system(\"git clone https://github.com/teavanist/MNIST-JPG.git\")\n",
    "    # Extract the zipfile containing the images\n",
    "    with ZipFile('MNIST-JPG/MNIST Dataset JPG format.zip', 'r') as zipObj:\n",
    "        # Extract all the contents of zip file in current directory\n",
    "        zipObj.extractall()\n",
    "    os.rename(\"MNIST Dataset JPG format\", \"MNIST\")\n",
    "    shutil.rmtree(\"MNIST-JPG\")\n",
    "    merge_folders(\"MNIST/MNIST - JPG - testing\")\n",
    "else:\n",
    "    print(\"Images Already Downloaded! Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_paths(data_directory):\n",
    "    class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "        \"\"\"Custom dataset that includes image file paths. Extends\n",
    "        torchvision.datasets.ImageFolder\n",
    "        Source: https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
    "        \"\"\"\n",
    "\n",
    "        # override the __getitem__ method. this is the method that dataloader calls\n",
    "        def __getitem__(self, index):\n",
    "            # this is what ImageFolder normally returns\n",
    "            original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "            # the image file path\n",
    "            path = self.imgs[index][0]\n",
    "            # make a new tuple that includes original and the path\n",
    "            tuple_with_path = original_tuple + (path,)\n",
    "            return tuple_with_path\n",
    "\n",
    "    def pooling_output(x, model):\n",
    "        for layer_name, layer in model._modules.items():\n",
    "            x = layer(x)\n",
    "            if layer_name == \"avgpool\":\n",
    "                break\n",
    "        return x\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=[224, 224], interpolation=2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = ImageFolderWithPaths(\n",
    "        data_directory, transform=transform\n",
    "    )  # our custom dataset\n",
    "    # strip away unnecessary info and store path to each image\n",
    "    img_paths = [dataset.imgs[i][0] for i in range(len(dataset.imgs))]\n",
    "    # initialize the dataloaders\n",
    "    dataloader = DataLoader(dataset)\n",
    "\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"[INFO] Using Device:\", DEVICE)\n",
    "    model = models.resnet101(pretrained=True, progress=True)\n",
    "    print(f\"[INFO] Loading model: {model.__class__.__name__}\")\n",
    "\n",
    "    features = []\n",
    "    print(f\"[INFO][STARTED] Feature Extraction using {model.__class__.__name__}\")\n",
    "    model.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs, labels, paths in tqdm(dataloader):\n",
    "            result = pooling_output(inputs.to(DEVICE), model)\n",
    "            features.append(result.cpu().view(1, -1).numpy())\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"[INFO][DONE] Feature Extraction using {model.__class__.__name__}\")\n",
    "\n",
    "    features = np.vstack(features)\n",
    "    print(\"[DEBUG]: Preview Features:\", features[0])\n",
    "    print(\"[DEBUG]: Preview Image Paths:\", img_paths[0])\n",
    "    return features, img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "925284843fe78a42911a9aa44fe3e6fa06df715c01b34c89d54238b67173471a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dropletDash')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
